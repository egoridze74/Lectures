#матстат 
$F_{\theta} = \{ F()x, \theta), \theta \in \Theta \}$
Точечным оцениванием называется построение оценки по какому-то параметру.

Если есть выборка объёма n, то любая статистика (функция выборки) может восприниматься как оценка.
$\vec{x} = (x_1, \dots, x_n)$, тогда $T(\vec{x})$ - статистика (оценка)

Пусть хотим построить оценку для $\theta$ $T(\vec{x}) \to \theta$
$\tau(T(\vec{x})) \to \tau(\theta)$ - не всегда прям круто

## Несмещённость
Статистика $T(\vec{x})$ называется **несмещённой оценкой** параметрической функции $\tau(\theta)$, если $$E T(\vec{x}) = \tau(\theta)$$, то есть мат ожидание в точности равно функции. Это значит, что мы оцениваем хорошо.

Пример:
Пусть у нас есть величина:
$\prod(\theta)$
Дана выборка объёма n:
$x_1, \dots, x_n$
$T_1(\vec{x}) = x_1(x_1 - 1)$
$E T_1(\vec{x}) = \sum\limits_{i = 0}^{\infty} i(i - 1) \cdot \frac{\theta^i e^{- \theta}}{i!} = \sum\limits_{i = 2}^{\infty} \frac{\theta^i e^{- \theta}}{(i - 2)!} = |i - 2 = j| = \sum\limits_{j = 0}^{\infty} \frac{\theta^{j + 2} e^{- \theta}}{j!} = \theta^2$ - несмещённая
$T_n(\vec{x}) = \frac{(\sum\limits_{i = 1}^{n} x_i)(\sum\limits_{i = 1}^{n} x_i - 1)}{n^2}$

$E T(\vec{x}) = \frac{1}{\theta} = \sum\limits_{(x_1, \dots, x_n) \in V_n} T(\vec{x}) \cdot \theta^{\sum x_i} (1 - \theta)^{n - \sum x_i} =$
$= \sum\limits_{t = 0}^{n} \theta^t (1 - \theta)^{n - t} \sum\limits_{(x_1, \dots, x_n): \ \sum x_i = t} T(\vec{x}) = \sum\limits_{t = 0}^{n} a(t) \cdot \theta^t (1 - \theta)^{n - t} \neq \frac{1}{\theta}$

## Состоятельность
Статистика $T(\vec{x})$ называется **состоятельной оценкой** для параметрической функции $\tau(\theta)$, если $$T(\vec{x}) \to^P \tau(\theta)$$ - [[Виды сходимости. Утверждения про виды сходимости|сходится по вероятности]]

Пример:
Есть выборка $x_1, \dots, x_n$, причём $x_i \sim F(x, \theta)$, $E x_i < \infty, \ D x_i < \infty$
$T(\vec{x}) = \frac{1}{n} \sum\limits_{i = 1}^{n} x_i$ - несмещённая и состоятельная оценка мат. ожидания

Проверим:
- $E T(\vec{x}) = \frac{1}{n} E \sum x_i = \frac{1}{n} \sum E x_i = \frac{n E x_1}{n} = E x_1 \implies$ несмещённость доказана
- $P(|\xi - E \xi| > \varepsilon) \leq \frac{D \xi}{\varepsilon^2}$
	$D T(\vec{x}) = D \frac{1}{n} \sum x_i = \frac{1}{n^2} \sum D x_i = \frac{n D x_1}{n^2} = \frac{D x_1}{n}$
	$0 \leq P(|\xi - E \xi| > \varepsilon) \leq \frac{D \xi}{\varepsilon^2} \to_{n \to \infty} 0$
	$\frac{1}{n} \sum\limits_{i = 1}^{n} x_i$ - выборочное среднее
	$\frac{1}{n} \sum\limits_{i = 1}^{n} x_i^k$ - выборочные k-ые моменты
	$\frac{1}{n} \sum\limits_{i = 1}^{n} (x_i - \overline{x})^k$ - k-ый выборочный центральный момент
	
	$k = 2 \implies \frac{1}{n} \sum\limits_{i = 1}^{n} (x_i - \overline{x})^2 = S^2$ - выборочная дисперсия
	$S_0^2 = \frac{1}{n - 1} \sum\limits_{i = 1}^{n} (x_i - \overline{x})^2$

Другой пример:
$П(\theta)$
$T_1(\vec{x}) = x_1(x_1 - 1)$
$D T(\vec{x}) \implies E T^2(\vec{x}) = \sum\limits_{i = 0}^{\infty} i^2(i - 1)^2 \frac{\theta^i e^{- \theta}}{i!} = \sum\limits_{i = 2}^{\infty} i(i - 1) \frac{\theta^i e^{- \theta}}{(i - 2)!} = |i - 2 = j| = \sum\limits_{j = 0}^{\infty} (j + 2)(j + 1) \frac{\theta^{j + 2} e^{- \theta}}{j!} =$
$= \theta^2 \sum\limits_{j = 0}^{\infty} (j^2 + 3j + 2) \frac{\theta^j e^{- \theta}}{j!} = \theta^2 (E x_1^2 + 3 E x_1 + 2) = \theta^2 (\theta^2 + \theta + 3 \theta + 2)$
У данной оценки сходимости по вероятности не будет, то есть, она не состоятельная