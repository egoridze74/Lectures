#машинка 
Задача машинного обучения - дойти до нужного значения целевой переменной.

Пусть есть:
- объекты $x_i \in x$
- целевая переменная $y_i \in \{0, 1\}$
Тогда $X = \{ (x_i, y_i) \}_{i = 1}^N$ - обучающая выборка

$x_i = \{ {x_i}_j \}_{j = 1}^d$ - **признаки**

**Признаки** могут быть:
- бинарными (частный случай категориальных)
- вещественными
- категориальными $\{1, 2, \dots, k\}$
- ординальные - упорядоченное множество (как категориальные, но их можно сравнить)
- set-valued (сложные признаки. Каждый признак - множество значений)
- связи с другими объектами

## Классы задач машинного обучения
### Обучение с учителем
Это когда обучающая выборка содержит целевую переменную, и мы её используем

$y_i$ - целевая переменная, $y_i \in Y$. Тогда выделяют такие подклассы задач:
- $Y = \mathbb{R}$ - **регрессия**
- $Y = \{ 0, 1 \}$ - **бинарная классификация**
- $Y = \{ 1, \dots, k \}$ - **мульти-классификация** (многоклассовая классификация, multi-class)
- $Y = \{ 0, 1 \}^k$ - **многоклассовая классификация с пересекающимися классами** (объекты могут принадлежать сразу нескольким классам, multi-label)

### Обучение без учителя
У нас нет целевой переменной, все признаки объекта значимы

Тогда выделяют такие подклассы задач:
- кластеризация (формируют ли данные какие-то закономерности)
- визуализация (выделить мало основных признаков, чтобы понять закономерности)
- понижение размерности (отсечь ненужные признаки)
- поиск аномалий

Пусть у нас есть матрица объектов и их признаков $N \times d$, где N - количество объектов, d - количество признаков. Такую матрицу обычно и используют для обучения моделей.